{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.017137,
     "end_time": "2020-08-24T11:08:44.452121",
     "exception": false,
     "start_time": "2020-08-24T11:08:44.434984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* V1: EfficientNet BaseLine: mix precision, label smoothing, mixup, same data augmentation(time mask, freque**ncy mask etc.)\n",
    "* V3: PANN ResNet38 BaseLine (BugFix):\n",
    "    https://github.com/qiuqiangkong/audioset_tagging_cnn\n",
    "* V4: PANN ResNet38: Without Mixup\n",
    "* V5: PANN ResNet38：Tmax=10\n",
    "* v7: PANN CNN14_DecesionLevelAttetnion， Based on: https://www.kaggle.com/hidehisaarai1213/introduction-to-sound-event-detection\n",
    "* v8: PANN CNN14_DecesionLevelAttetnion，with mixup, and label smoothing.\n",
    "* v9: Change metric from f1score(macro) to f1score(micro), Epoch:100\n",
    "* V12: Create SimpleBalanceSampler ResNet38.\n",
    "* V14: ResNet38 without SimpleBalanceSampler\n",
    "* V15: OOF, Based on: https://www.kaggle.com/shonenkov/competition-metrics \n",
    "* V16：V15 BugFix\n",
    "* V17：Wavegram_Logmel_Cnn14 + Attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-08-24T11:08:44.481532Z",
     "iopub.status.busy": "2020-08-24T11:08:44.480534Z",
     "iopub.status.idle": "2020-08-24T11:09:14.849393Z",
     "shell.execute_reply": "2020-08-24T11:09:14.849949Z"
    },
    "papermill": {
     "duration": 30.385461,
     "end_time": "2020-08-24T11:09:14.850157",
     "exception": false,
     "start_time": "2020-08-24T11:08:44.464696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/bird-panns/torchlibrosa-master/torchlibrosa-master\n",
      "Building wheels for collected packages: torchlibrosa\n",
      "  Building wheel for torchlibrosa (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torchlibrosa: filename=torchlibrosa-0.0.4-py3-none-any.whl size=8864 sha256=e02a39e86692c9a7c00b1148ab6172eeb8b67bdf79edb2d1246515648b3c65c7\n",
      "  Stored in directory: /root/.cache/pip/wheels/52/35/08/7a90aa926e1403318b7b36ba5a03ad940bd5002dad343b8c1f\n",
      "Successfully built torchlibrosa\n",
      "Installing collected packages: torchlibrosa\n",
      "Successfully installed torchlibrosa-0.0.4\n"
     ]
    }
   ],
   "source": [
    "# !pip install ../input/bird-panns/torchlibrosa-master/torchlibrosa-master/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:14.884595Z",
     "iopub.status.busy": "2020-08-24T11:09:14.881289Z",
     "iopub.status.idle": "2020-08-24T11:09:18.837595Z",
     "shell.execute_reply": "2020-08-24T11:09:18.838219Z"
    },
    "papermill": {
     "duration": 3.976312,
     "end_time": "2020-08-24T11:09:18.838395",
     "exception": false,
     "start_time": "2020-08-24T11:09:14.862083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import warnings\n",
    "import typing as tp\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from joblib import delayed, Parallel\n",
    "\n",
    "import cv2\n",
    "import librosa\n",
    "import audioread\n",
    "import soundfile as sf\n",
    "import librosa.display \n",
    "from fastprogress import progress_bar\n",
    "from scipy.io import wavfile\n",
    "from librosa.core import resample, to_mono\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data.sampler import Sampler\n",
    "\n",
    "#from efficientnet_pytorch import EfficientNet\n",
    "#from apex import amp\n",
    "from torchlibrosa import Spectrogram, LogmelFilterBank\n",
    "from torchlibrosa import SpecAugmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:18.868818Z",
     "iopub.status.busy": "2020-08-24T11:09:18.868133Z",
     "iopub.status.idle": "2020-08-24T11:09:18.872043Z",
     "shell.execute_reply": "2020-08-24T11:09:18.872482Z"
    },
    "papermill": {
     "duration": 0.022249,
     "end_time": "2020-08-24T11:09:18.872607",
     "exception": false,
     "start_time": "2020-08-24T11:09:18.850358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    period= 5\n",
    "    num_fold = 5\n",
    "    num_class = 264\n",
    "    num_workers = 2\n",
    "    \n",
    "    ####################\n",
    "    #training parameters\n",
    "    ####################\n",
    "    verbose = True\n",
    "    verbose_step = 1\n",
    "    folder = '0914panns'\n",
    "    use_mixup = True\n",
    "    use_amp = False\n",
    "    accumulate_steps = 1\n",
    "    batch_size = 32\n",
    "    lr = 1e-3\n",
    "    n_epochs = 50\n",
    "    weight_decay = 0\n",
    "    \n",
    "    step_scheduler = False\n",
    "    validation_scheduler = True\n",
    "    SchedulerClass = torch.optim.lr_scheduler.CosineAnnealingLR\n",
    "    scheduler_params = dict(\n",
    "        T_max=n_epochs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:18.901551Z",
     "iopub.status.busy": "2020-08-24T11:09:18.900797Z",
     "iopub.status.idle": "2020-08-24T11:09:18.906750Z",
     "shell.execute_reply": "2020-08-24T11:09:18.906203Z"
    },
    "papermill": {
     "duration": 0.022952,
     "end_time": "2020-08-24T11:09:18.906850",
     "exception": false,
     "start_time": "2020-08-24T11:09:18.883898",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "set_seed()\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:18.940303Z",
     "iopub.status.busy": "2020-08-24T11:09:18.939535Z",
     "iopub.status.idle": "2020-08-24T11:09:19.208068Z",
     "shell.execute_reply": "2020-08-24T11:09:19.206941Z"
    },
    "papermill": {
     "duration": 0.289251,
     "end_time": "2020-08-24T11:09:19.208204",
     "exception": false,
     "start_time": "2020-08-24T11:09:18.918953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ROOT = Path.cwd().parent\n",
    "# INPUT_ROOT = ROOT / \"input\"\n",
    "INPUT_ROOT = Path(\"/home/knikaido/work/Cornell-Birdcall-Identification/data\")\n",
    "RAW_DATA = INPUT_ROOT / \"birdsong-recognition\"\n",
    "TRAIN_AUDIO_DIR = RAW_DATA / \"train_audio\"\n",
    "TRAIN_RESAMPLED_AUDIO_DIRS = [\n",
    "    INPUT_ROOT / \"birdsong-resampled-train-audio-{:0>2}\".format(i)  for i in range(5)\n",
    "]\n",
    "\n",
    "TEST_AUDIO_DIR = RAW_DATA / \"test_audio\"\n",
    "\n",
    "train = pd.read_csv(TRAIN_RESAMPLED_AUDIO_DIRS[0] / \"train_mod.csv\")\n",
    "TRAIN_RESAMPLED_AUDIO_DIRS = [\n",
    "  INPUT_ROOT / \"birdsong-resampled-train-audio-hpss-npz\"\n",
    "]\n",
    "for i in range(len(train)):\n",
    "    train['resampled_filename'][i] = train['resampled_filename'][i][:-4] + '.npy'\n",
    "\n",
    "if not TEST_AUDIO_DIR.exists():\n",
    "    TEST_AUDIO_DIR = INPUT_ROOT / \"birdcall-check\" / \"test_audio\"\n",
    "    test = pd.read_csv(INPUT_ROOT / \"birdcall-check\" / \"test.csv\")\n",
    "else:\n",
    "    test = pd.read_csv(RAW_DATA / \"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011212,
     "end_time": "2020-08-24T11:09:19.231274",
     "exception": false,
     "start_time": "2020-08-24T11:09:19.220062",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Split Train/Val DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:19.262916Z",
     "iopub.status.busy": "2020-08-24T11:09:19.262086Z",
     "iopub.status.idle": "2020-08-24T11:09:20.068799Z",
     "shell.execute_reply": "2020-08-24T11:09:20.068225Z"
    },
    "papermill": {
     "duration": 0.826255,
     "end_time": "2020-08-24T11:09:20.068921",
     "exception": false,
     "start_time": "2020-08-24T11:09:19.242666",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21375, 38)\n",
      "(21375, 3)\n",
      "(21375, 39)\n"
     ]
    }
   ],
   "source": [
    "tmp_list = []\n",
    "for audio_d in TRAIN_RESAMPLED_AUDIO_DIRS:\n",
    "    if not audio_d.exists():\n",
    "        continue\n",
    "    for ebird_d in audio_d.iterdir():\n",
    "        if ebird_d.is_file():\n",
    "            continue\n",
    "        for wav_f in ebird_d.iterdir():\n",
    "            tmp_list.append([ebird_d.name, wav_f.name, wav_f.as_posix()])\n",
    "            \n",
    "train_wav_path_exist = pd.DataFrame(\n",
    "    tmp_list, columns=[\"ebird_code\", \"resampled_filename\", \"file_path\"])\n",
    "\n",
    "del tmp_list\n",
    "\n",
    "train_all = pd.merge(\n",
    "    train, train_wav_path_exist, on=[\"ebird_code\", \"resampled_filename\"], how=\"inner\")\n",
    "\n",
    "print(train.shape)\n",
    "print(train_wav_path_exist.shape)\n",
    "print(train_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:20.122036Z",
     "iopub.status.busy": "2020-08-24T11:09:20.116396Z",
     "iopub.status.idle": "2020-08-24T11:09:20.192520Z",
     "shell.execute_reply": "2020-08-24T11:09:20.191638Z"
    },
    "papermill": {
     "duration": 0.11189,
     "end_time": "2020-08-24T11:09:20.192636",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.080746",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(264, 5)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(config.num_fold)\n",
    "\n",
    "train_all[\"fold\"] = -1\n",
    "for fold_id, (train_index, val_index) in enumerate(skf.split(train_all, train_all[\"ebird_code\"])):\n",
    "    train_all.iloc[val_index, -1] = fold_id\n",
    "    \n",
    "# # check the propotion\n",
    "fold_proportion = pd.pivot_table(train_all, index=\"ebird_code\", \n",
    "                                 columns=\"fold\", values=\"xc_id\", aggfunc=len)\n",
    "print(fold_proportion.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:20.226807Z",
     "iopub.status.busy": "2020-08-24T11:09:20.226033Z",
     "iopub.status.idle": "2020-08-24T11:09:20.275171Z",
     "shell.execute_reply": "2020-08-24T11:09:20.274290Z"
    },
    "papermill": {
     "duration": 0.070404,
     "end_time": "2020-08-24T11:09:20.275289",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.204885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fold 0] train: 17100, val: 4275\n"
     ]
    }
   ],
   "source": [
    "use_fold = 0\n",
    "train_file_list = train_all.query(\"fold != @use_fold\")[[\"file_path\", \"ebird_code\"]].values.tolist()\n",
    "val_file_list = train_all.query(\"fold == @use_fold\")[[\"file_path\", \"ebird_code\"]].values.tolist()\n",
    "\n",
    "print(\"[fold {}] train: {}, val: {}\".format(use_fold, len(train_file_list), len(val_file_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01143,
     "end_time": "2020-08-24T11:09:20.298902",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.287472",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Make Labels Dectionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:20.345370Z",
     "iopub.status.busy": "2020-08-24T11:09:20.329792Z",
     "iopub.status.idle": "2020-08-24T11:09:20.363141Z",
     "shell.execute_reply": "2020-08-24T11:09:20.362627Z"
    },
    "papermill": {
     "duration": 0.052934,
     "end_time": "2020-08-24T11:09:20.363241",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.310307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/ttahara/training-birdsong-baseline-resnest50-fast\n",
    "BIRD_CODE = {\n",
    "    'aldfly': 0, 'ameavo': 1, 'amebit': 2, 'amecro': 3, 'amegfi': 4,\n",
    "    'amekes': 5, 'amepip': 6, 'amered': 7, 'amerob': 8, 'amewig': 9,\n",
    "    'amewoo': 10, 'amtspa': 11, 'annhum': 12, 'astfly': 13, 'baisan': 14,\n",
    "    'baleag': 15, 'balori': 16, 'banswa': 17, 'barswa': 18, 'bawwar': 19,\n",
    "    'belkin1': 20, 'belspa2': 21, 'bewwre': 22, 'bkbcuc': 23, 'bkbmag1': 24,\n",
    "    'bkbwar': 25, 'bkcchi': 26, 'bkchum': 27, 'bkhgro': 28, 'bkpwar': 29,\n",
    "    'bktspa': 30, 'blkpho': 31, 'blugrb1': 32, 'blujay': 33, 'bnhcow': 34,\n",
    "    'boboli': 35, 'bongul': 36, 'brdowl': 37, 'brebla': 38, 'brespa': 39,\n",
    "    'brncre': 40, 'brnthr': 41, 'brthum': 42, 'brwhaw': 43, 'btbwar': 44,\n",
    "    'btnwar': 45, 'btywar': 46, 'buffle': 47, 'buggna': 48, 'buhvir': 49,\n",
    "    'bulori': 50, 'bushti': 51, 'buwtea': 52, 'buwwar': 53, 'cacwre': 54,\n",
    "    'calgul': 55, 'calqua': 56, 'camwar': 57, 'cangoo': 58, 'canwar': 59,\n",
    "    'canwre': 60, 'carwre': 61, 'casfin': 62, 'caster1': 63, 'casvir': 64,\n",
    "    'cedwax': 65, 'chispa': 66, 'chiswi': 67, 'chswar': 68, 'chukar': 69,\n",
    "    'clanut': 70, 'cliswa': 71, 'comgol': 72, 'comgra': 73, 'comloo': 74,\n",
    "    'commer': 75, 'comnig': 76, 'comrav': 77, 'comred': 78, 'comter': 79,\n",
    "    'comyel': 80, 'coohaw': 81, 'coshum': 82, 'cowscj1': 83, 'daejun': 84,\n",
    "    'doccor': 85, 'dowwoo': 86, 'dusfly': 87, 'eargre': 88, 'easblu': 89,\n",
    "    'easkin': 90, 'easmea': 91, 'easpho': 92, 'eastow': 93, 'eawpew': 94,\n",
    "    'eucdov': 95, 'eursta': 96, 'evegro': 97, 'fiespa': 98, 'fiscro': 99,\n",
    "    'foxspa': 100, 'gadwal': 101, 'gcrfin': 102, 'gnttow': 103, 'gnwtea': 104,\n",
    "    'gockin': 105, 'gocspa': 106, 'goleag': 107, 'grbher3': 108, 'grcfly': 109,\n",
    "    'greegr': 110, 'greroa': 111, 'greyel': 112, 'grhowl': 113, 'grnher': 114,\n",
    "    'grtgra': 115, 'grycat': 116, 'gryfly': 117, 'haiwoo': 118, 'hamfly': 119,\n",
    "    'hergul': 120, 'herthr': 121, 'hoomer': 122, 'hoowar': 123, 'horgre': 124,\n",
    "    'horlar': 125, 'houfin': 126, 'houspa': 127, 'houwre': 128, 'indbun': 129,\n",
    "    'juntit1': 130, 'killde': 131, 'labwoo': 132, 'larspa': 133, 'lazbun': 134,\n",
    "    'leabit': 135, 'leafly': 136, 'leasan': 137, 'lecthr': 138, 'lesgol': 139,\n",
    "    'lesnig': 140, 'lesyel': 141, 'lewwoo': 142, 'linspa': 143, 'lobcur': 144,\n",
    "    'lobdow': 145, 'logshr': 146, 'lotduc': 147, 'louwat': 148, 'macwar': 149,\n",
    "    'magwar': 150, 'mallar3': 151, 'marwre': 152, 'merlin': 153, 'moublu': 154,\n",
    "    'mouchi': 155, 'moudov': 156, 'norcar': 157, 'norfli': 158, 'norhar2': 159,\n",
    "    'normoc': 160, 'norpar': 161, 'norpin': 162, 'norsho': 163, 'norwat': 164,\n",
    "    'nrwswa': 165, 'nutwoo': 166, 'olsfly': 167, 'orcwar': 168, 'osprey': 169,\n",
    "    'ovenbi1': 170, 'palwar': 171, 'pasfly': 172, 'pecsan': 173, 'perfal': 174,\n",
    "    'phaino': 175, 'pibgre': 176, 'pilwoo': 177, 'pingro': 178, 'pinjay': 179,\n",
    "    'pinsis': 180, 'pinwar': 181, 'plsvir': 182, 'prawar': 183, 'purfin': 184,\n",
    "    'pygnut': 185, 'rebmer': 186, 'rebnut': 187, 'rebsap': 188, 'rebwoo': 189,\n",
    "    'redcro': 190, 'redhea': 191, 'reevir1': 192, 'renpha': 193, 'reshaw': 194,\n",
    "    'rethaw': 195, 'rewbla': 196, 'ribgul': 197, 'rinduc': 198, 'robgro': 199,\n",
    "    'rocpig': 200, 'rocwre': 201, 'rthhum': 202, 'ruckin': 203, 'rudduc': 204,\n",
    "    'rufgro': 205, 'rufhum': 206, 'rusbla': 207, 'sagspa1': 208, 'sagthr': 209,\n",
    "    'savspa': 210, 'saypho': 211, 'scatan': 212, 'scoori': 213, 'semplo': 214,\n",
    "    'semsan': 215, 'sheowl': 216, 'shshaw': 217, 'snobun': 218, 'snogoo': 219,\n",
    "    'solsan': 220, 'sonspa': 221, 'sora': 222, 'sposan': 223, 'spotow': 224,\n",
    "    'stejay': 225, 'swahaw': 226, 'swaspa': 227, 'swathr': 228, 'treswa': 229,\n",
    "    'truswa': 230, 'tuftit': 231, 'tunswa': 232, 'veery': 233, 'vesspa': 234,\n",
    "    'vigswa': 235, 'warvir': 236, 'wesblu': 237, 'wesgre': 238, 'weskin': 239,\n",
    "    'wesmea': 240, 'wessan': 241, 'westan': 242, 'wewpew': 243, 'whbnut': 244,\n",
    "    'whcspa': 245, 'whfibi': 246, 'whtspa': 247, 'whtswi': 248, 'wilfly': 249,\n",
    "    'wilsni1': 250, 'wiltur': 251, 'winwre3': 252, 'wlswar': 253, 'wooduc': 254,\n",
    "    'wooscj2': 255, 'woothr': 256, 'y00475': 257, 'yebfly': 258, 'yebsap': 259,\n",
    "    'yehbla': 260, 'yelwar': 261, 'yerwar': 262, 'yetvir': 263\n",
    "}\n",
    "\n",
    "INV_BIRD_CODE = {v: k for k, v in BIRD_CODE.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:20.395723Z",
     "iopub.status.busy": "2020-08-24T11:09:20.392008Z",
     "iopub.status.idle": "2020-08-24T11:09:20.477906Z",
     "shell.execute_reply": "2020-08-24T11:09:20.477371Z"
    },
    "papermill": {
     "duration": 0.103418,
     "end_time": "2020-08-24T11:09:20.478016",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.374598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ebird_codes =  train_all.query(\"fold != @use_fold\")[\"ebird_code\"].values.tolist()\n",
    "all_targets = []\n",
    "for i in range(len(ebird_codes)):\n",
    "    ebird_code = ebird_codes[i]\n",
    "    labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
    "    labels[BIRD_CODE[ebird_code]] = 1\n",
    "    all_targets.append(labels)\n",
    "    \n",
    "all_targets = np.array(all_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011395,
     "end_time": "2020-08-24T11:09:20.501528",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.490133",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:20.539269Z",
     "iopub.status.busy": "2020-08-24T11:09:20.538324Z",
     "iopub.status.idle": "2020-08-24T11:09:20.541161Z",
     "shell.execute_reply": "2020-08-24T11:09:20.540625Z"
    },
    "papermill": {
     "duration": 0.028075,
     "end_time": "2020-08-24T11:09:20.541271",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.513196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SimpleBalanceClassSampler(Sampler):\n",
    "\n",
    "    def __init__(self, targets, classes_num):\n",
    "\n",
    "        self.targets = targets\n",
    "        self.classes_num = classes_num\n",
    "        \n",
    "        self.samples_num_per_class = np.sum(self.targets, axis=0)\n",
    "        self.max_num = np.max(self.samples_num_per_class)\n",
    "        \n",
    "        self.indexes_per_class = []\n",
    "        # Training indexes of all sound classes. E.g.: \n",
    "        # [[0, 11, 12, ...], [3, 4, 15, 16, ...], [7, 8, ...], ...]\n",
    "        for k in range(self.classes_num):\n",
    "            self.indexes_per_class.append(\n",
    "                np.where(self.targets[:, k] == 1)[0])\n",
    "        \n",
    "        self.length = self.classes_num * self.max_num\n",
    "\n",
    "    def __iter__(self):\n",
    "        \n",
    "        all_indexs = []\n",
    "        \n",
    "        for k in range(self.classes_num):\n",
    "            if len(self.indexes_per_class[k]) == self.max_num:\n",
    "                all_indexs.append(self.indexes_per_class[k])\n",
    "            else:\n",
    "                gap = self.max_num - len(self.indexes_per_class[k])\n",
    "                random_choice = np.random.choice(self.indexes_per_class[k], int(gap), replace=True)\n",
    "                all_indexs.append(np.array(list(random_choice) + list(self.indexes_per_class[k])))\n",
    "                \n",
    "        l = np.stack(all_indexs).T\n",
    "        l = l.reshape(-1)\n",
    "        random.shuffle(l)\n",
    "        return iter(l)\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(self.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:20.579800Z",
     "iopub.status.busy": "2020-08-24T11:09:20.577220Z",
     "iopub.status.idle": "2020-08-24T11:09:20.582531Z",
     "shell.execute_reply": "2020-08-24T11:09:20.582064Z"
    },
    "papermill": {
     "duration": 0.029903,
     "end_time": "2020-08-24T11:09:20.582624",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.552721",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class birddataset(data.Dataset):\n",
    "    \"\"\"\n",
    "    Based On\n",
    "    https://www.kaggle.com/ttahara/training-birdsong-baseline-resnest50-fast/data?\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, file_list, test=False, label_smooth=True):\n",
    "        \n",
    "        self.file_list = file_list\n",
    "        self.label_smooth = label_smooth\n",
    "        self.test = test\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        \n",
    "        wav_path, ebird_code = self.file_list[idx]\n",
    "        wave, sr = sf.read(wav_path)\n",
    "        effective_length = sr * config.period\n",
    "        if len(wave) < effective_length:\n",
    "            new_wave = np.zeros(effective_length, dtype=wave.dtype)\n",
    "            start = np.random.randint(effective_length - len(wave))\n",
    "            new_wave[start:start + len(wave)] = wave\n",
    "            wave = new_wave.astype(np.float32)\n",
    "        elif len(wave) > effective_length:\n",
    "            start = np.random.randint(len(wave) - effective_length)\n",
    "            wave = wave[start:start + effective_length].astype(np.float32)\n",
    "        else:\n",
    "            wave= wave.astype(np.float32)\n",
    "        \n",
    "        labels = np.zeros(len(BIRD_CODE), dtype=\"f\")\n",
    "        labels[BIRD_CODE[ebird_code]] = 1\n",
    "        if self.label_smooth and self.test == False:\n",
    "            labels = self.make_label_smooth(labels, num_classes=config.num_class)\n",
    "        \n",
    "        return {\"waveform\": wave, \"targets\": labels}\n",
    "    \n",
    "    def make_label_smooth(self, labels, num_classes, epsilon=0.1):\n",
    "        b = np.ones(num_classes) * (1 / num_classes)\n",
    "        return (1 - epsilon) * labels + epsilon * b "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.011394,
     "end_time": "2020-08-24T11:09:20.605754",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.594360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:20.637450Z",
     "iopub.status.busy": "2020-08-24T11:09:20.636718Z",
     "iopub.status.idle": "2020-08-24T11:09:20.639787Z",
     "shell.execute_reply": "2020-08-24T11:09:20.639308Z"
    },
    "papermill": {
     "duration": 0.022426,
     "end_time": "2020-08-24T11:09:20.639880",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.617454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mixup(object):\n",
    "    def __init__(self, mixup_alpha, random_seed=1234):\n",
    "        \"\"\"Mixup coefficient generator.\n",
    "        \"\"\"\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "        self.random_state = np.random.RandomState(random_seed)\n",
    "\n",
    "    def get_lambda(self, batch_size):\n",
    "        \"\"\"Get mixup random coefficients.\n",
    "        Args:\n",
    "          batch_size: int\n",
    "        Returns:\n",
    "          mixup_lambdas: (batch_size,)\n",
    "        \"\"\"\n",
    "        mixup_lambdas = []\n",
    "        for n in range(0, batch_size, 2):\n",
    "            lam = self.random_state.beta(self.mixup_alpha, self.mixup_alpha, 1)[0]\n",
    "            mixup_lambdas.append(lam)\n",
    "            mixup_lambdas.append(1. - lam)\n",
    "\n",
    "        return np.array(mixup_lambdas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:20.669247Z",
     "iopub.status.busy": "2020-08-24T11:09:20.668450Z",
     "iopub.status.idle": "2020-08-24T11:09:20.671414Z",
     "shell.execute_reply": "2020-08-24T11:09:20.670947Z"
    },
    "papermill": {
     "duration": 0.019912,
     "end_time": "2020-08-24T11:09:20.671505",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.651593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def do_mixup(x, mixup_lambda):\n",
    "    \"\"\"Mixup x of even indexes (0, 2, 4, ...) with x of odd indexes \n",
    "    (1, 3, 5, ...).\n",
    "    Args:\n",
    "      x: (batch_size * 2, ...)\n",
    "      mixup_lambda: (batch_size * 2,)\n",
    "    Returns:\n",
    "      out: (batch_size, ...)\n",
    "    \"\"\"\n",
    "    out = (x[0 :: 2].transpose(0, -1) * mixup_lambda[0 :: 2] + \\\n",
    "        x[1 :: 2].transpose(0, -1) * mixup_lambda[1 :: 2]).transpose(0, -1)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:20.702097Z",
     "iopub.status.busy": "2020-08-24T11:09:20.701179Z",
     "iopub.status.idle": "2020-08-24T11:09:20.703991Z",
     "shell.execute_reply": "2020-08-24T11:09:20.703478Z"
    },
    "papermill": {
     "duration": 0.020649,
     "end_time": "2020-08-24T11:09:20.704079",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.683430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def init_layer(layer):\n",
    "    \"\"\"Initialize a Linear or Convolutional layer. \"\"\"\n",
    "    nn.init.xavier_uniform_(layer.weight)\n",
    " \n",
    "    if hasattr(layer, 'bias'):\n",
    "        if layer.bias is not None:\n",
    "            layer.bias.data.fill_(0.)\n",
    "            \n",
    "    \n",
    "def init_bn(bn):\n",
    "    \"\"\"Initialize a Batchnorm layer. \"\"\"\n",
    "    bn.bias.data.fill_(0.)\n",
    "    bn.weight.data.fill_(1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:20.734100Z",
     "iopub.status.busy": "2020-08-24T11:09:20.733289Z",
     "iopub.status.idle": "2020-08-24T11:09:20.736074Z",
     "shell.execute_reply": "2020-08-24T11:09:20.735494Z"
    },
    "papermill": {
     "duration": 0.0204,
     "end_time": "2020-08-24T11:09:20.736162",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.715762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _resnet_conv3x3(in_planes, out_planes):\n",
    "    #3x3 convolution with padding\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=1,\n",
    "                     padding=1, groups=1, bias=False, dilation=1)\n",
    "\n",
    "\n",
    "def _resnet_conv1x1(in_planes, out_planes):\n",
    "    #1x1 convolution\n",
    "    return nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=1, bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:20.777431Z",
     "iopub.status.busy": "2020-08-24T11:09:20.773233Z",
     "iopub.status.idle": "2020-08-24T11:09:20.780402Z",
     "shell.execute_reply": "2020-08-24T11:09:20.779817Z"
    },
    "papermill": {
     "duration": 0.032288,
     "end_time": "2020-08-24T11:09:20.780498",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.748210",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class _ResnetBasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, groups=1,\n",
    "                 base_width=64, dilation=1, norm_layer=None):\n",
    "        super(_ResnetBasicBlock, self).__init__()\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        if groups != 1 or base_width != 64:\n",
    "            raise ValueError('_ResnetBasicBlock only supports groups=1 and base_width=64')\n",
    "        if dilation > 1:\n",
    "            raise NotImplementedError(\"Dilation > 1 not supported in _ResnetBasicBlock\")\n",
    "        # Both self.conv1 and self.downsample layers downsample the input when stride != 1\n",
    "\n",
    "        self.stride = stride\n",
    "\n",
    "        self.conv1 = _resnet_conv3x3(inplanes, planes)\n",
    "        self.bn1 = norm_layer(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = _resnet_conv3x3(planes, planes)\n",
    "        self.bn2 = norm_layer(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_bn(self.bn1)\n",
    "        init_layer(self.conv2)\n",
    "        init_bn(self.bn2)\n",
    "        nn.init.constant_(self.bn2.weight, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        if self.stride == 2:\n",
    "            out = F.avg_pool2d(x, kernel_size=(2, 2))\n",
    "        else:\n",
    "            out = x\n",
    "\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = F.dropout(out, p=0.1, training=self.training)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:20.820085Z",
     "iopub.status.busy": "2020-08-24T11:09:20.812606Z",
     "iopub.status.idle": "2020-08-24T11:09:20.823153Z",
     "shell.execute_reply": "2020-08-24T11:09:20.822690Z"
    },
    "papermill": {
     "duration": 0.03014,
     "end_time": "2020-08-24T11:09:20.823243",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.793103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=in_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=(3, 3), stride=(1, 1),\n",
    "                              padding=(1, 1), bias=False)\n",
    "                              \n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=(3, 3), stride=(1, 1),\n",
    "                              padding=(1, 1), bias=False)\n",
    "                              \n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.init_weight()\n",
    "        \n",
    "    def init_weight(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "\n",
    "        \n",
    "    def forward(self, input, pool_size=(2, 2), pool_type='avg'):\n",
    "        \n",
    "        x = input\n",
    "        x = F.relu_(self.bn1(self.conv1(x)))\n",
    "        x = F.relu_(self.bn2(self.conv2(x)))\n",
    "        if pool_type == 'max':\n",
    "            x = F.max_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg':\n",
    "            x = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "        elif pool_type == 'avg+max':\n",
    "            x1 = F.avg_pool2d(x, kernel_size=pool_size)\n",
    "            x2 = F.max_pool2d(x, kernel_size=pool_size)\n",
    "            x = x1 + x2\n",
    "        else:\n",
    "            raise Exception('Incorrect argument!')\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:20.870786Z",
     "iopub.status.busy": "2020-08-24T11:09:20.859883Z",
     "iopub.status.idle": "2020-08-24T11:09:20.873010Z",
     "shell.execute_reply": "2020-08-24T11:09:20.873467Z"
    },
    "papermill": {
     "duration": 0.038443,
     "end_time": "2020-08-24T11:09:20.873570",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.835127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class _ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, zero_init_residual=False,\n",
    "                 groups=1, width_per_group=64, replace_stride_with_dilation=None,\n",
    "                 norm_layer=None):\n",
    "        super(_ResNet, self).__init__()\n",
    "\n",
    "        if norm_layer is None:\n",
    "            norm_layer = nn.BatchNorm2d\n",
    "        self._norm_layer = norm_layer\n",
    "\n",
    "        self.inplanes = 64\n",
    "        self.dilation = 1\n",
    "        if replace_stride_with_dilation is None:\n",
    "            # each element in the tuple indicates if we should replace\n",
    "            # the 2x2 stride with a dilated convolution instead\n",
    "            replace_stride_with_dilation = [False, False, False]\n",
    "        if len(replace_stride_with_dilation) != 3:\n",
    "            raise ValueError(\"replace_stride_with_dilation should be None \"\n",
    "                             \"or a 3-element tuple, got {}\".format(replace_stride_with_dilation))\n",
    "        self.groups = groups\n",
    "        self.base_width = width_per_group\n",
    "\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[0])\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[1])\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2,\n",
    "                                       dilate=replace_stride_with_dilation[2])\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilate=False):\n",
    "        norm_layer = self._norm_layer\n",
    "        downsample = None\n",
    "        previous_dilation = self.dilation\n",
    "        if dilate:\n",
    "            self.dilation *= stride\n",
    "            stride = 1\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            if stride == 1:\n",
    "                downsample = nn.Sequential(\n",
    "                    _resnet_conv1x1(self.inplanes, planes * block.expansion),\n",
    "                    norm_layer(planes * block.expansion),\n",
    "                )\n",
    "                init_layer(downsample[0])\n",
    "                init_bn(downsample[1])\n",
    "            elif stride == 2:\n",
    "                downsample = nn.Sequential(\n",
    "                    nn.AvgPool2d(kernel_size=2), \n",
    "                    _resnet_conv1x1(self.inplanes, planes * block.expansion),\n",
    "                    norm_layer(planes * block.expansion),\n",
    "                )\n",
    "                init_layer(downsample[1])\n",
    "                init_bn(downsample[2])\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, self.groups,\n",
    "                            self.base_width, previous_dilation, norm_layer))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, groups=self.groups,\n",
    "                                base_width=self.base_width, dilation=self.dilation,\n",
    "                                norm_layer=norm_layer))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:20.915596Z",
     "iopub.status.busy": "2020-08-24T11:09:20.905234Z",
     "iopub.status.idle": "2020-08-24T11:09:20.926851Z",
     "shell.execute_reply": "2020-08-24T11:09:20.926366Z"
    },
    "papermill": {
     "duration": 0.041242,
     "end_time": "2020-08-24T11:09:20.926945",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.885703",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet38(nn.Module):\n",
    "    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, fmax, classes_num):\n",
    "        \n",
    "        super(ResNet38, self).__init__()\n",
    "\n",
    "        window = 'hann'\n",
    "        center = True\n",
    "        pad_mode = 'reflect'\n",
    "        ref = 1.0\n",
    "        amin = 1e-10\n",
    "        top_db = None\n",
    "\n",
    "        # Spectrogram extractor\n",
    "        self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n",
    "            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n",
    "            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
    "            freq_drop_width=8, freq_stripes_num=2)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv_block1 = ConvBlock(in_channels=1, out_channels=64)\n",
    "        # self.conv_block2 = ConvBlock(in_channels=64, out_channels=64)\n",
    "\n",
    "        self.resnet = _ResNet(block=_ResnetBasicBlock, layers=[3, 4, 6, 3], zero_init_residual=True)\n",
    "\n",
    "        self.conv_block_after1 = ConvBlock(in_channels=512, out_channels=2048)\n",
    "\n",
    "        self.fc1 = nn.Linear(2048, 2048)\n",
    "        self.fc_audioset = nn.Linear(2048, classes_num, bias=True)\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_bn(self.bn0)\n",
    "        init_layer(self.fc1)\n",
    "        init_layer(self.fc_audioset)\n",
    "\n",
    "\n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        \"\"\"\n",
    "        Input: (batch_size, data_length)\"\"\"\n",
    "\n",
    "        x = self.spectrogram_extractor(input)   # (batch_size, 1, time_steps, freq_bins)\n",
    "        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n",
    "        \n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "        \n",
    "        if self.training:\n",
    "            x = self.spec_augmenter(x)\n",
    "\n",
    "        # Mixup on spectrogram\n",
    "        if self.training and mixup_lambda is not None:\n",
    "            x = do_mixup(x, mixup_lambda)\n",
    "        \n",
    "        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training, inplace=True)\n",
    "        x = self.resnet(x)\n",
    "        x = F.avg_pool2d(x, kernel_size=(2, 2))\n",
    "        x = F.dropout(x, p=0.2, training=self.training, inplace=True)\n",
    "        x = self.conv_block_after1(x, pool_size=(1, 1), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training, inplace=True)\n",
    "        x = torch.mean(x, dim=3)\n",
    "        \n",
    "        (x1, _) = torch.max(x, dim=2)\n",
    "        x2 = torch.mean(x, dim=2)\n",
    "        x = x1 + x2\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        embedding = F.dropout(x, p=0.5, training=self.training)\n",
    "        clipwise_output = torch.sigmoid(self.fc_audioset(x))\n",
    "        \n",
    "        output_dict = {'clipwise_output': clipwise_output, 'embedding': embedding}\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:20.969505Z",
     "iopub.status.busy": "2020-08-24T11:09:20.958981Z",
     "iopub.status.idle": "2020-08-24T11:09:21.000995Z",
     "shell.execute_reply": "2020-08-24T11:09:21.000472Z"
    },
    "papermill": {
     "duration": 0.062094,
     "end_time": "2020-08-24T11:09:21.001105",
     "exception": false,
     "start_time": "2020-08-24T11:09:20.939011",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConvPreWavBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        \n",
    "        super(ConvPreWavBlock, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=in_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=3, stride=1,\n",
    "                              padding=1, bias=False)\n",
    "                              \n",
    "        self.conv2 = nn.Conv1d(in_channels=out_channels, \n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=3, stride=1, dilation=2, \n",
    "                              padding=2, bias=False)\n",
    "                              \n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "        self.init_weight()\n",
    "        \n",
    "    def init_weight(self):\n",
    "        init_layer(self.conv1)\n",
    "        init_layer(self.conv2)\n",
    "        init_bn(self.bn1)\n",
    "        init_bn(self.bn2)\n",
    "\n",
    "        \n",
    "    def forward(self, input, pool_size):\n",
    "        \n",
    "        x = input\n",
    "        x = F.relu_(self.bn1(self.conv1(x)))\n",
    "        x = F.relu_(self.bn2(self.conv2(x)))\n",
    "        x = F.max_pool1d(x, kernel_size=pool_size)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class Wavegram_Logmel_Cnn14(nn.Module):\n",
    "    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, \n",
    "        fmax, classes_num):\n",
    "        \n",
    "        super(Wavegram_Logmel_Cnn14, self).__init__()\n",
    "\n",
    "        window = 'hann'\n",
    "        center = True\n",
    "        pad_mode = 'reflect'\n",
    "        ref = 1.0\n",
    "        amin = 1e-10\n",
    "        top_db = None\n",
    "\n",
    "        self.pre_conv0 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=11, stride=5, padding=5, bias=False)\n",
    "        self.pre_bn0 = nn.BatchNorm1d(64)\n",
    "        self.pre_block1 = ConvPreWavBlock(64, 64)\n",
    "        self.pre_block2 = ConvPreWavBlock(64, 128)\n",
    "        self.pre_block3 = ConvPreWavBlock(128, 128)\n",
    "        self.pre_block4 = ConvBlock(in_channels=4, out_channels=64)\n",
    "\n",
    "        # Spectrogram extractor\n",
    "        self.spectrogram_extractor = Spectrogram(n_fft=window_size, hop_length=hop_size, \n",
    "            win_length=window_size, window=window, center=center, pad_mode=pad_mode, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(sr=sample_rate, n_fft=window_size, \n",
    "            n_mels=mel_bins, fmin=fmin, fmax=fmax, ref=ref, amin=amin, top_db=top_db, \n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2, \n",
    "            freq_drop_width=8, freq_stripes_num=2)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.conv_block1 = ConvBlock(in_channels=1, out_channels=64)\n",
    "        self.conv_block2 = ConvBlock(in_channels=128, out_channels=128)\n",
    "        self.conv_block3 = ConvBlock(in_channels=128, out_channels=256)\n",
    "        self.conv_block4 = ConvBlock(in_channels=256, out_channels=512)\n",
    "        self.conv_block5 = ConvBlock(in_channels=512, out_channels=1024)\n",
    "        self.conv_block6 = ConvBlock(in_channels=1024, out_channels=2048)\n",
    "\n",
    "        self.fc1 = nn.Linear(2048, 2048, bias=True)\n",
    "        self.fc_audioset = nn.Linear(2048, classes_num, bias=True)\n",
    "        \n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_layer(self.pre_conv0)\n",
    "        init_bn(self.pre_bn0)\n",
    "        init_bn(self.bn0)\n",
    "        init_layer(self.fc1)\n",
    "        init_layer(self.fc_audioset)\n",
    " \n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        \"\"\"\n",
    "        Input: (batch_size, data_length)\"\"\"\n",
    "\n",
    "        # Wavegram\n",
    "        a1 = F.relu_(self.pre_bn0(self.pre_conv0(input[:, None, :])))\n",
    "        a1 = self.pre_block1(a1, pool_size=4)\n",
    "        a1 = self.pre_block2(a1, pool_size=4)\n",
    "        a1 = self.pre_block3(a1, pool_size=4)\n",
    "        a1 = a1.reshape((a1.shape[0], -1, 32, a1.shape[-1])).transpose(2, 3)\n",
    "        a1 = self.pre_block4(a1, pool_size=(2, 1))\n",
    "\n",
    "        # Log mel spectrogram\n",
    "        x = self.spectrogram_extractor(input)   # (batch_size, 1, time_steps, freq_bins)\n",
    "        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n",
    "        \n",
    "        frames_num = x.shape[2]\n",
    "        \n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "\n",
    "        if self.training:\n",
    "            x = self.spec_augmenter(x)\n",
    "\n",
    "        # Mixup on spectrogram\n",
    "        if self.training and mixup_lambda is not None:\n",
    "            x = do_mixup(x, mixup_lambda)\n",
    "            a1 = do_mixup(a1, mixup_lambda)\n",
    "        \n",
    "        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n",
    "\n",
    "        # Concatenate Wavegram and Log mel spectrogram along the channel dimension\n",
    "        x = torch.cat((x, a1), dim=1)\n",
    "\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block2(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block3(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block4(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block5(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block6(x, pool_size=(1, 1), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x_ = torch.mean(x, dim=3)\n",
    "        \n",
    "        (x1, _) = torch.max(x_, dim=2)\n",
    "        x2 = torch.mean(x_, dim=2)\n",
    "        x = x1 + x2\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        embedding = F.dropout(x, p=0.5, training=self.training)\n",
    "        clipwise_output = torch.sigmoid(self.fc_audioset(x))\n",
    "        \n",
    "        output_dict = {'frames_num': frames_num, 'embedding': x_, }\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:21.054066Z",
     "iopub.status.busy": "2020-08-24T11:09:21.038334Z",
     "iopub.status.idle": "2020-08-24T11:09:21.079063Z",
     "shell.execute_reply": "2020-08-24T11:09:21.079489Z"
    },
    "papermill": {
     "duration": 0.066433,
     "end_time": "2020-08-24T11:09:21.079597",
     "exception": false,
     "start_time": "2020-08-24T11:09:21.013164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def interpolate(x: torch.Tensor, ratio: int):\n",
    "    \"\"\"Interpolate data in time domain. This is used to compensate the\n",
    "    resolution reduction in downsampling of a CNN.\n",
    "\n",
    "    Args:\n",
    "      x: (batch_size, time_steps, classes_num)\n",
    "      ratio: int, ratio to interpolate\n",
    "    Returns:\n",
    "      upsampled: (batch_size, time_steps * ratio, classes_num)\n",
    "    \"\"\"\n",
    "    (batch_size, time_steps, classes_num) = x.shape\n",
    "    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n",
    "    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n",
    "    return upsampled\n",
    "\n",
    "\n",
    "def pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n",
    "    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n",
    "    is the same as the value of the last frame.\n",
    "    Args:\n",
    "      framewise_output: (batch_size, frames_num, classes_num)\n",
    "      frames_num: int, number of frames to pad\n",
    "    Outputs:\n",
    "      output: (batch_size, frames_num, classes_num)\n",
    "    \"\"\"\n",
    "    pad = framewise_output[:, -1:, :].repeat(\n",
    "        1, frames_num - framewise_output.shape[1], 1)\n",
    "    \"\"\"tensor for padding\"\"\"\n",
    "\n",
    "    output = torch.cat((framewise_output, pad), dim=1)\n",
    "    \"\"\"(batch_size, frames_num, classes_num)\"\"\"\n",
    "\n",
    "    return output\n",
    "\n",
    "class AttBlock(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features: int,\n",
    "                 out_features: int,\n",
    "                 activation=\"linear\",\n",
    "                 temperature=1.0):\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "        self.temperature = temperature\n",
    "        self.att = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "        self.cla = nn.Conv1d(\n",
    "            in_channels=in_features,\n",
    "            out_channels=out_features,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=True)\n",
    "\n",
    "        self.bn_att = nn.BatchNorm1d(out_features)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        init_layer(self.att)\n",
    "        init_layer(self.cla)\n",
    "        init_bn(self.bn_att)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (n_samples, n_in, n_time)\n",
    "        norm_att = torch.softmax(torch.clamp(self.att(x), -10, 10), dim=-1)\n",
    "        cla = self.nonlinear_transform(self.cla(x))\n",
    "        x = torch.sum(norm_att * cla, dim=2)\n",
    "        return x, norm_att, cla\n",
    "\n",
    "    def nonlinear_transform(self, x):\n",
    "        if self.activation == 'linear':\n",
    "            return x\n",
    "        elif self.activation == 'sigmoid':\n",
    "            return torch.sigmoid(x)\n",
    "        \n",
    "class PANNsCNN14Att(nn.Module):\n",
    "    \n",
    "    def __init__(self, sample_rate: int, window_size: int, hop_size: int,\n",
    "                 mel_bins: int, fmin: int, fmax: int, classes_num: int):\n",
    "        super().__init__()\n",
    "\n",
    "        window = 'hann'\n",
    "        center = True\n",
    "        pad_mode = 'reflect'\n",
    "        ref = 1.0\n",
    "        amin = 1e-10\n",
    "        top_db = None\n",
    "        self.interpolate_ratio = 32  # Downsampled ratio\n",
    "\n",
    "        # Spectrogram extractor\n",
    "        self.spectrogram_extractor = Spectrogram(\n",
    "            n_fft=window_size,\n",
    "            hop_length=hop_size,\n",
    "            win_length=window_size,\n",
    "            window=window,\n",
    "            center=center,\n",
    "            pad_mode=pad_mode,\n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Logmel feature extractor\n",
    "        self.logmel_extractor = LogmelFilterBank(\n",
    "            sr=sample_rate,\n",
    "            n_fft=window_size,\n",
    "            n_mels=mel_bins,\n",
    "            fmin=fmin,\n",
    "            fmax=fmax,\n",
    "            ref=ref,\n",
    "            amin=amin,\n",
    "            top_db=top_db,\n",
    "            freeze_parameters=True)\n",
    "\n",
    "        # Spec augmenter\n",
    "        self.spec_augmenter = SpecAugmentation(\n",
    "            time_drop_width=64,\n",
    "            time_stripes_num=2,\n",
    "            freq_drop_width=8,\n",
    "            freq_stripes_num=2)\n",
    "\n",
    "        self.bn0 = nn.BatchNorm2d(mel_bins)\n",
    "\n",
    "        self.conv_block1 = ConvBlock(in_channels=1, out_channels=64)\n",
    "        self.conv_block2 = ConvBlock(in_channels=64, out_channels=128)\n",
    "        self.conv_block3 = ConvBlock(in_channels=128, out_channels=256)\n",
    "        self.conv_block4 = ConvBlock(in_channels=256, out_channels=512)\n",
    "        self.conv_block5 = ConvBlock(in_channels=512, out_channels=1024)\n",
    "        self.conv_block6 = ConvBlock(in_channels=1024, out_channels=2048)\n",
    "\n",
    "        self.fc1 = nn.Linear(2048, 2048, bias=True)\n",
    "        self.att_block = AttBlock(2048, classes_num, activation='sigmoid')\n",
    "\n",
    "        self.init_weight()\n",
    "\n",
    "    def init_weight(self):\n",
    "        init_bn(self.bn0)\n",
    "        init_layer(self.fc1)\n",
    "        \n",
    "    def cnn_feature_extractor(self, x):\n",
    "        x = self.conv_block1(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block2(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block3(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block4(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block5(x, pool_size=(2, 2), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        x = self.conv_block6(x, pool_size=(1, 1), pool_type='avg')\n",
    "        x = F.dropout(x, p=0.2, training=self.training)\n",
    "        return x\n",
    "    \n",
    "    def preprocess(self, input, mixup_lambda=None):\n",
    "        # t1 = time.time()\n",
    "        x = self.spectrogram_extractor(input)  # (batch_size, 1, time_steps, freq_bins)\n",
    "        x = self.logmel_extractor(x)  # (batch_size, 1, time_steps, mel_bins)\n",
    "\n",
    "        frames_num = x.shape[2]\n",
    "\n",
    "        x = x.transpose(1, 3)\n",
    "        x = self.bn0(x)\n",
    "        x = x.transpose(1, 3)\n",
    "\n",
    "        if self.training:\n",
    "            x = self.spec_augmenter(x)\n",
    "\n",
    "        # Mixup on spectrogram\n",
    "        if self.training and mixup_lambda is not None:\n",
    "            x = do_mixup(x, mixup_lambda)\n",
    "        return x, frames_num\n",
    "        \n",
    "\n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        \"\"\"\n",
    "        Input: (batch_size, data_length)\"\"\"\n",
    "        x, frames_num = self.preprocess(input, mixup_lambda=mixup_lambda)\n",
    "        # Output shape (batch size, channels, time, frequency)\n",
    "        x = self.cnn_feature_extractor(x)\n",
    "        \n",
    "        # Aggregate in frequency axis\n",
    "        x = torch.mean(x, dim=3)\n",
    "        print(x.size())\n",
    "\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        print(x.size())\n",
    "\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        # Get framewise output\n",
    "        framewise_output = interpolate(segmentwise_output,\n",
    "                                       self.interpolate_ratio)\n",
    "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "\n",
    "        output_dict = {\n",
    "            'framewise_output': framewise_output,\n",
    "            'clipwise_output': clipwise_output\n",
    "        }\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.012057,
     "end_time": "2020-08-24T11:09:21.104041",
     "exception": false,
     "start_time": "2020-08-24T11:09:21.091984",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:21.144840Z",
     "iopub.status.busy": "2020-08-24T11:09:21.141188Z",
     "iopub.status.idle": "2020-08-24T11:09:21.147605Z",
     "shell.execute_reply": "2020-08-24T11:09:21.147039Z"
    },
    "papermill": {
     "duration": 0.031385,
     "end_time": "2020-08-24T11:09:21.147710",
     "exception": false,
     "start_time": "2020-08-24T11:09:21.116325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transfer_Cnn14(nn.Module):\n",
    "    def __init__(self, sample_rate, window_size, hop_size, mel_bins, fmin, fmax, classes_num):\n",
    "        super(Transfer_Cnn14, self).__init__()\n",
    "        audioset_classes_num = 527\n",
    "        \n",
    "        self.base = Wavegram_Logmel_Cnn14(sample_rate, window_size, \n",
    "                                          hop_size, mel_bins, fmin,\n",
    "                                          fmax, audioset_classes_num)\n",
    "\n",
    "        # Transfer to another task layer\n",
    "        self.fc1 = nn.Linear(2048, 2048, bias=True)\n",
    "        self.att_block = AttBlock(2048, classes_num, activation='sigmoid')\n",
    "        self.interpolate_ratio = 32\n",
    "        self.init_weight()\n",
    "    def init_weight(self):\n",
    "        init_layer(self.fc1)\n",
    "        \n",
    "    def load_from_pretrain(self, pretrained_checkpoint_path):\n",
    "        checkpoint = torch.load(pretrained_checkpoint_path)\n",
    "        self.base.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    def forward(self, input, mixup_lambda=None):\n",
    "        \"\"\"Input: (batch_size, data_length)\n",
    "        \"\"\"\n",
    "        base_output = self.base(input, mixup_lambda)\n",
    "        x = base_output['embedding']\n",
    "        frames_num = base_output['frames_num']\n",
    "        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n",
    "        x = x1 + x2\n",
    "\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.relu_(self.fc1(x))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n",
    "        segmentwise_output = segmentwise_output.transpose(1, 2)\n",
    "\n",
    "        # Get framewise output\n",
    "        framewise_output = interpolate(segmentwise_output,\n",
    "                                       self.interpolate_ratio)\n",
    "        framewise_output = pad_framewise_output(framewise_output, frames_num)\n",
    "\n",
    "        output_dict = {\n",
    "            'framewise_output': framewise_output,\n",
    "            'clipwise_output': clipwise_output\n",
    "        }\n",
    "\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:21.178267Z",
     "iopub.status.busy": "2020-08-24T11:09:21.177471Z",
     "iopub.status.idle": "2020-08-24T11:09:21.179979Z",
     "shell.execute_reply": "2020-08-24T11:09:21.180460Z"
    },
    "papermill": {
     "duration": 0.020804,
     "end_time": "2020-08-24T11:09:21.180566",
     "exception": false,
     "start_time": "2020-08-24T11:09:21.159762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(num_classes, pretrained=False):\n",
    "    \n",
    "    model_config = {\n",
    "        \"sample_rate\": 32000,\n",
    "        \"window_size\": 1024,\n",
    "        \"hop_size\": 320,\n",
    "        \"mel_bins\": 64,\n",
    "        \"fmin\": 50,\n",
    "        \"fmax\": 14000,\n",
    "        }\n",
    "\n",
    "    model_config[\"classes_num\"] = num_classes\n",
    "    model = Transfer_Cnn14(**model_config)\n",
    "    if pretrained:\n",
    "        model.load_from_pretrain(\"../data/bird-panns/Wavegram_Logmel_Cnn14_mAP0.439.pth\")\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.012381,
     "end_time": "2020-08-24T11:09:21.205375",
     "exception": false,
     "start_time": "2020-08-24T11:09:21.192994",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:21.237256Z",
     "iopub.status.busy": "2020-08-24T11:09:21.236443Z",
     "iopub.status.idle": "2020-08-24T11:09:21.239348Z",
     "shell.execute_reply": "2020-08-24T11:09:21.238785Z"
    },
    "papermill": {
     "duration": 0.021752,
     "end_time": "2020-08-24T11:09:21.239441",
     "exception": false,
     "start_time": "2020-08-24T11:09:21.217689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:21.268631Z",
     "iopub.status.busy": "2020-08-24T11:09:21.267889Z",
     "iopub.status.idle": "2020-08-24T11:09:21.270361Z",
     "shell.execute_reply": "2020-08-24T11:09:21.270900Z"
    },
    "papermill": {
     "duration": 0.019128,
     "end_time": "2020-08-24T11:09:21.271020",
     "exception": false,
     "start_time": "2020-08-24T11:09:21.251892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clip_bce(output_dict, target_dict):\n",
    "    \"\"\"Binary crossentropy loss.\n",
    "    \"\"\"\n",
    "    return F.binary_cross_entropy(\n",
    "        output_dict['clipwise_output'], target_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:21.303625Z",
     "iopub.status.busy": "2020-08-24T11:09:21.302829Z",
     "iopub.status.idle": "2020-08-24T11:09:21.305885Z",
     "shell.execute_reply": "2020-08-24T11:09:21.305354Z"
    },
    "papermill": {
     "duration": 0.022016,
     "end_time": "2020-08-24T11:09:21.305979",
     "exception": false,
     "start_time": "2020-08-24T11:09:21.283963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/hidehisaarai1213/introduction-to-sound-event-detection\n",
    "class PANNsLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bce = nn.BCELoss()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        input_ = input[\"clipwise_output\"]\n",
    "        input_ = torch.where(torch.isnan(input_),\n",
    "                             torch.zeros_like(input_),\n",
    "                             input_)\n",
    "\n",
    "        target = target.float()\n",
    "\n",
    "        return self.bce(input_, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:21.334769Z",
     "iopub.status.busy": "2020-08-24T11:09:21.333852Z",
     "iopub.status.idle": "2020-08-24T11:09:21.380947Z",
     "shell.execute_reply": "2020-08-24T11:09:21.381413Z"
    },
    "papermill": {
     "duration": 0.062961,
     "end_time": "2020-08-24T11:09:21.381529",
     "exception": false,
     "start_time": "2020-08-24T11:09:21.318568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Fitter:\n",
    "    \n",
    "    def __init__(self, model, device, config):\n",
    "        self.config = config\n",
    "        self.epoch = 0\n",
    "\n",
    "        self.base_dir = f'./{config.folder}'\n",
    "        if not os.path.exists(self.base_dir):\n",
    "            os.makedirs(self.base_dir)\n",
    "        \n",
    "        self.log_path = f'{self.base_dir}/log.txt'\n",
    "        self.best_summary_loss = 10**5\n",
    "        self.best_score = 0.0\n",
    "        self.early_stop_count = 0\n",
    "        \n",
    "        self.model = model\n",
    "        self.device = device\n",
    "        self.use_amp = config.use_amp\n",
    "        self.accumulate_steps = config.accumulate_steps\n",
    "        self.model.to(self.device)\n",
    "        self.use_mixup = config.use_mixup\n",
    "        self.threshold = 0.5\n",
    "        \n",
    "        if self.use_mixup:\n",
    "            self.mixup_augmenter = Mixup(mixup_alpha=1.)\n",
    "        self.loss_fn = PANNsLoss()\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=config.lr, weight_decay=config.weight_decay)\n",
    "        \n",
    "        if self.use_amp:\n",
    "            self.model, self.optimizer = amp.initialize(self.model, self.optimizer, opt_level=\"O1\",verbosity=0)\n",
    "        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n",
    "        self.log(f'Fitter prepared. Device is {self.device}')\n",
    "\n",
    "    def fit(self, train_loader, validation_loader):\n",
    "        \n",
    "        best_epoch = 0\n",
    "        for e in range(self.config.n_epochs):\n",
    "            if self.early_stop_count == 10:\n",
    "                self.log(f'early stopping: Epoch: {self.epoch}')\n",
    "            if self.config.verbose:\n",
    "                lr = self.optimizer.param_groups[0]['lr']\n",
    "                timestamp = datetime.utcnow().isoformat()\n",
    "                self.log(f'\\n{timestamp}\\nLR: {lr}')\n",
    "\n",
    "            t = time.time()\n",
    "            summary_loss = self.train_one_epoch(train_loader)\n",
    "\n",
    "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, time: {(time.time() - t):.5f}')\n",
    "            self.save(f'{self.base_dir}/last-checkpoint.bin')\n",
    "\n",
    "            t = time.time()\n",
    "            summary_loss, f1_score, acc_score = self.validation(self.model, validation_loader)\n",
    "\n",
    "            self.log(f'[RESULT]: Val. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, val_f1_score: {f1_score:.5f}, val_acc_score: {acc_score:.5f}, time: {(time.time() - t):.5f}')\n",
    "            if summary_loss.avg < self.best_summary_loss:\n",
    "                self.best_summary_loss = summary_loss.avg\n",
    "                self.model.eval()\n",
    "                self.save(f'{self.base_dir}/best-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n",
    "                for path in sorted(glob(f'{self.base_dir}/best-checkpoint-*epoch.bin'))[:-3]:\n",
    "                    os.remove(path)\n",
    "            else:\n",
    "                self.early_stop_count += 1\n",
    "            if f1_score > self.best_score:\n",
    "                self.best_score = f1_score\n",
    "                self.model.eval()\n",
    "                self.save(f'{self.base_dir}/best-acc-checkpoint.bin')\n",
    "\n",
    "            if self.config.validation_scheduler:\n",
    "                self.scheduler.step()\n",
    "\n",
    "            self.epoch += 1\n",
    "            \n",
    "            \n",
    "    def validation(self, model, val_loader):\n",
    "        model.eval()\n",
    "        summary_loss = AverageMeter()\n",
    "        t = time.time()\n",
    "        pred_results  = []\n",
    "        origin_labels = []\n",
    "        \n",
    "        for step, batch_data_dict in enumerate(val_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Val Step {step}/{len(val_loader)}, ' + \\\n",
    "                        f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            with torch.no_grad():\n",
    "                batch_size = batch_data_dict['waveform'].shape[0]\n",
    "                batch_output_dict = self.model(torch.FloatTensor(batch_data_dict['waveform']).cuda(), None)\n",
    "                batch_target_dict = {'target': torch.FloatTensor(batch_data_dict['targets']).cuda()}\n",
    "                loss = clip_bce(batch_output_dict, batch_target_dict['target'])\n",
    "                \n",
    "                proba = batch_output_dict['clipwise_output'].detach().cpu().numpy()\n",
    "                y_pred = proba.argmax(axis=1)\n",
    "                y_true = batch_data_dict['targets'].argmax(axis=1)\n",
    "                \n",
    "                pred_results.append(y_pred)\n",
    "                origin_labels.append(y_true)\n",
    "                \n",
    "                summary_loss.update(loss.detach().item(), batch_size)\n",
    "            \n",
    "        pred_results = np.concatenate(pred_results)    \n",
    "        origin_labels = np.concatenate(origin_labels)\n",
    "        val_f1_score = f1_score(origin_labels, pred_results, average='macro')\n",
    "        val_accuracy_score = accuracy_score(origin_labels, pred_results)\n",
    "\n",
    "        return summary_loss, val_f1_score, val_accuracy_score\n",
    "\n",
    "    def train_one_epoch(self, train_loader):\n",
    "        self.model.train()\n",
    "        summary_loss = AverageMeter()\n",
    "        t = time.time()\n",
    "        self.optimizer.zero_grad() #very important\n",
    "        for step, batch_data_dict in enumerate(train_loader):\n",
    "            if self.config.verbose:\n",
    "                if step % self.config.verbose_step == 0:\n",
    "                    print(\n",
    "                        f'Train Step {step}/{len(train_loader)}, ' + \\\n",
    "                        f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n",
    "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
    "                    )\n",
    "            batch_size = batch_data_dict['waveform'].shape[0]\n",
    "            \n",
    "            if self.use_mixup:\n",
    "                batch_data_dict['mixup_lambda'] = self.mixup_augmenter.get_lambda(len(batch_data_dict['waveform']))\n",
    "                batch_size = batch_size//2\n",
    "                batch_output_dict = self.model(torch.FloatTensor(batch_data_dict['waveform']).cuda(), \n",
    "                                               torch.FloatTensor(batch_data_dict['mixup_lambda']).cuda())\n",
    "                batch_target_dict = {'target': torch.FloatTensor(do_mixup(batch_data_dict['targets'], \n",
    "                                                                          batch_data_dict['mixup_lambda'][:, np.newaxis])).cuda()}\n",
    "            else:\n",
    "                batch_output_dict = self.model(torch.FloatTensor(batch_data_dict['waveform']).cuda(), None)\n",
    "                batch_target_dict = {'target': torch.FloatTensor(batch_data_dict['targets']).cuda()}\n",
    "            \n",
    "            loss = clip_bce(batch_output_dict, batch_target_dict['target'])\n",
    "            if self.use_amp:\n",
    "                with amp.scale_loss(loss, self.optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "            else:\n",
    "                loss.backward()\n",
    "            if (step+1) % self.accumulate_steps == 0: # Wait for several backward steps\n",
    "                self.optimizer.step()                 # Now we can do an optimizer step\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "            summary_loss.update(loss.detach().item(), batch_size)\n",
    "\n",
    "            if self.config.step_scheduler:\n",
    "                self.scheduler.step()\n",
    "\n",
    "            \n",
    "        return summary_loss\n",
    "    \n",
    "    def save(self, path):\n",
    "        self.model.eval()\n",
    "        torch.save({'model_state_dict': self.model.state_dict()}, path)\n",
    "        \n",
    "    def log(self, message):\n",
    "        if self.config.verbose:\n",
    "            print(message)\n",
    "        with open(self.log_path, 'a+') as logger:\n",
    "            logger.write(f'{message}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:21.412372Z",
     "iopub.status.busy": "2020-08-24T11:09:21.411600Z",
     "iopub.status.idle": "2020-08-24T11:09:21.414068Z",
     "shell.execute_reply": "2020-08-24T11:09:21.414537Z"
    },
    "papermill": {
     "duration": 0.020489,
     "end_time": "2020-08-24T11:09:21.414642",
     "exception": false,
     "start_time": "2020-08-24T11:09:21.394153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def collate_fn(list_data_dict):\n",
    "    \"\"\"Collate data.\n",
    "    Args:\n",
    "      list_data_dict, e.g., [{'waveform': (clip_samples,), ...}, \n",
    "                             {'waveform': (clip_samples,), ...},\n",
    "                             ...]\n",
    "    Returns:\n",
    "      np_data_dict, dict, e.g.,\n",
    "          {'waveform': (batch_size, clip_samples), ...}\n",
    "    \"\"\"\n",
    "    np_data_dict = {}\n",
    "    \n",
    "    for key in list_data_dict[0].keys():\n",
    "        #[print(data_dict[key].shape) for data_dict in list_data_dict]\n",
    "        np_data_dict[key] = np.array([data_dict[key] for data_dict in list_data_dict])\n",
    "    \n",
    "    return np_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:21.449061Z",
     "iopub.status.busy": "2020-08-24T11:09:21.448270Z",
     "iopub.status.idle": "2020-08-24T11:09:21.451197Z",
     "shell.execute_reply": "2020-08-24T11:09:21.450733Z"
    },
    "papermill": {
     "duration": 0.023992,
     "end_time": "2020-08-24T11:09:21.451290",
     "exception": false,
     "start_time": "2020-08-24T11:09:21.427298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_training(net, config):\n",
    "    device = torch.device('cuda:0')\n",
    "    \n",
    "    train_dataset = birddataset(train_file_list, label_smooth=False, test=False)\n",
    "    validation_dataset = birddataset(val_file_list, label_smooth=False, test=True)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=config.batch_size, #*2 if config.use_mixup else config.batch_size,\n",
    "        sampler=SimpleBalanceClassSampler(all_targets, config.num_class),\n",
    "        pin_memory=False,\n",
    "        drop_last=True,\n",
    "        collate_fn=collate_fn,\n",
    "        num_workers=config.num_workers,\n",
    "    )\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        validation_dataset, \n",
    "        batch_size=config.batch_size,\n",
    "        num_workers=config.num_workers,\n",
    "        shuffle=False,\n",
    "        collate_fn = collate_fn,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "\n",
    "    fitter = Fitter(model=net, device=device, config=config)\n",
    "    fitter.fit(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016218,
     "end_time": "2020-08-24T11:09:21.480236",
     "exception": false,
     "start_time": "2020-08-24T11:09:21.464018",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-08-24T11:09:21.529114Z",
     "iopub.status.busy": "2020-08-24T11:09:21.528029Z",
     "iopub.status.idle": "2020-08-24T17:07:28.442875Z",
     "shell.execute_reply": "2020-08-24T17:07:28.443387Z"
    },
    "papermill": {
     "duration": 21486.94098,
     "end_time": "2020-08-24T17:07:28.443580",
     "exception": false,
     "start_time": "2020-08-24T11:09:21.502600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitter prepared. Device is cuda:0\n",
      "\n",
      "2020-08-24T11:09:29.496170\n",
      "LR: 0.001\n",
      "[RESULT]: Train. Epoch: 0, summary_loss: 0.03060, time: 343.76765\n",
      "[RESULT]: Val. Epoch: 0, summary_loss: 0.02331, val_f1_score: 0.04312, val_acc_score: 0.07719, time: 63.05800\n",
      "\n",
      "2020-08-24T11:16:17.965797\n",
      "LR: 0.0009990133642141358\n",
      "[RESULT]: Train. Epoch: 1, summary_loss: 0.02234, time: 346.25383\n",
      "[RESULT]: Val. Epoch: 1, summary_loss: 0.01914, val_f1_score: 0.15519, val_acc_score: 0.19228, time: 51.01824\n",
      "\n",
      "2020-08-24T11:22:57.141585\n",
      "LR: 0.000996057350657239\n",
      "[RESULT]: Train. Epoch: 2, summary_loss: 0.02026, time: 343.96568\n",
      "[RESULT]: Val. Epoch: 2, summary_loss: 0.01762, val_f1_score: 0.24907, val_acc_score: 0.27228, time: 45.41207\n",
      "\n",
      "2020-08-24T11:29:28.449012\n",
      "LR: 0.0009911436253643444\n",
      "[RESULT]: Train. Epoch: 3, summary_loss: 0.01904, time: 340.24373\n",
      "[RESULT]: Val. Epoch: 3, summary_loss: 0.01622, val_f1_score: 0.28720, val_acc_score: 0.30877, time: 50.72282\n",
      "\n",
      "2020-08-24T11:36:01.247903\n",
      "LR: 0.0009842915805643156\n",
      "[RESULT]: Train. Epoch: 4, summary_loss: 0.01821, time: 341.54966\n",
      "[RESULT]: Val. Epoch: 4, summary_loss: 0.01502, val_f1_score: 0.35136, val_acc_score: 0.37029, time: 58.31896\n",
      "\n",
      "2020-08-24T11:42:43.265044\n",
      "LR: 0.0009755282581475769\n",
      "[RESULT]: Train. Epoch: 5, summary_loss: 0.01767, time: 348.52614\n",
      "[RESULT]: Val. Epoch: 5, summary_loss: 0.01457, val_f1_score: 0.39059, val_acc_score: 0.40795, time: 57.34420\n",
      "\n",
      "2020-08-24T11:49:31.209351\n",
      "LR: 0.0009648882429441258\n",
      "[RESULT]: Train. Epoch: 6, summary_loss: 0.01722, time: 346.58025\n",
      "[RESULT]: Val. Epoch: 6, summary_loss: 0.01406, val_f1_score: 0.42511, val_acc_score: 0.44842, time: 60.03164\n",
      "\n",
      "2020-08-24T11:56:19.633785\n",
      "LR: 0.0009524135262330099\n",
      "[RESULT]: Train. Epoch: 7, summary_loss: 0.01673, time: 356.08141\n",
      "[RESULT]: Val. Epoch: 7, summary_loss: 0.01404, val_f1_score: 0.43401, val_acc_score: 0.45216, time: 68.31299\n",
      "\n",
      "2020-08-24T12:03:25.881555\n",
      "LR: 0.0009381533400219318\n",
      "[RESULT]: Train. Epoch: 8, summary_loss: 0.01640, time: 362.69547\n",
      "[RESULT]: Val. Epoch: 8, summary_loss: 0.01391, val_f1_score: 0.45015, val_acc_score: 0.46199, time: 68.02779\n",
      "\n",
      "2020-08-24T12:10:38.601248\n",
      "LR: 0.0009221639627510075\n",
      "[RESULT]: Train. Epoch: 9, summary_loss: 0.01599, time: 349.24802\n",
      "[RESULT]: Val. Epoch: 9, summary_loss: 0.01312, val_f1_score: 0.46537, val_acc_score: 0.48585, time: 64.63223\n",
      "\n",
      "2020-08-24T12:17:34.444762\n",
      "LR: 0.0009045084971874736\n",
      "[RESULT]: Train. Epoch: 10, summary_loss: 0.01574, time: 349.64108\n",
      "[RESULT]: Val. Epoch: 10, summary_loss: 0.01280, val_f1_score: 0.47455, val_acc_score: 0.49263, time: 63.69589\n",
      "\n",
      "2020-08-24T12:24:29.720566\n",
      "LR: 0.0008852566213878945\n",
      "[RESULT]: Train. Epoch: 11, summary_loss: 0.01552, time: 347.86190\n",
      "[RESULT]: Val. Epoch: 11, summary_loss: 0.01280, val_f1_score: 0.48897, val_acc_score: 0.50643, time: 61.87679\n",
      "\n",
      "2020-08-24T12:31:20.833742\n",
      "LR: 0.0008644843137107056\n",
      "[RESULT]: Train. Epoch: 12, summary_loss: 0.01524, time: 348.64141\n",
      "[RESULT]: Val. Epoch: 12, summary_loss: 0.01237, val_f1_score: 0.50633, val_acc_score: 0.52094, time: 63.16689\n",
      "\n",
      "2020-08-24T12:38:14.626158\n",
      "LR: 0.0008422735529643443\n",
      "[RESULT]: Train. Epoch: 13, summary_loss: 0.01488, time: 367.07946\n",
      "[RESULT]: Val. Epoch: 13, summary_loss: 0.01209, val_f1_score: 0.51181, val_acc_score: 0.53287, time: 71.69064\n",
      "\n",
      "2020-08-24T12:45:35.326163\n",
      "LR: 0.0008187119948743448\n",
      "[RESULT]: Train. Epoch: 14, summary_loss: 0.01483, time: 351.39177\n",
      "[RESULT]: Val. Epoch: 14, summary_loss: 0.01276, val_f1_score: 0.50434, val_acc_score: 0.51275, time: 59.85896\n",
      "\n",
      "2020-08-24T12:52:27.251993\n",
      "LR: 0.0007938926261462366\n",
      "[RESULT]: Train. Epoch: 15, summary_loss: 0.01457, time: 347.27407\n",
      "[RESULT]: Val. Epoch: 15, summary_loss: 0.01258, val_f1_score: 0.51723, val_acc_score: 0.52982, time: 57.84561\n",
      "\n",
      "2020-08-24T12:59:13.785708\n",
      "LR: 0.0007679133974894982\n",
      "[RESULT]: Train. Epoch: 16, summary_loss: 0.01444, time: 344.35421\n",
      "[RESULT]: Val. Epoch: 16, summary_loss: 0.01258, val_f1_score: 0.51432, val_acc_score: 0.52936, time: 49.89762\n",
      "\n",
      "2020-08-24T13:05:48.709110\n",
      "LR: 0.0007408768370508576\n",
      "[RESULT]: Train. Epoch: 17, summary_loss: 0.01422, time: 343.11877\n",
      "[RESULT]: Val. Epoch: 17, summary_loss: 0.01306, val_f1_score: 0.52067, val_acc_score: 0.53942, time: 47.39627\n",
      "\n",
      "2020-08-24T13:12:20.620376\n",
      "LR: 0.0007128896457825362\n",
      "[RESULT]: Train. Epoch: 18, summary_loss: 0.01398, time: 343.53645\n",
      "[RESULT]: Val. Epoch: 18, summary_loss: 0.01204, val_f1_score: 0.54032, val_acc_score: 0.55860, time: 40.82818\n",
      "\n",
      "2020-08-24T13:18:47.054066\n",
      "LR: 0.0006840622763423389\n",
      "[RESULT]: Train. Epoch: 19, summary_loss: 0.01385, time: 341.15360\n",
      "[RESULT]: Val. Epoch: 19, summary_loss: 0.01240, val_f1_score: 0.54275, val_acc_score: 0.55883, time: 46.23278\n",
      "\n",
      "2020-08-24T13:25:16.022171\n",
      "LR: 0.0006545084971874735\n",
      "[RESULT]: Train. Epoch: 20, summary_loss: 0.01366, time: 340.98849\n",
      "[RESULT]: Val. Epoch: 20, summary_loss: 0.01230, val_f1_score: 0.55401, val_acc_score: 0.56749, time: 44.85247\n",
      "\n",
      "2020-08-24T13:31:43.267877\n",
      "LR: 0.0006243449435824271\n",
      "[RESULT]: Train. Epoch: 21, summary_loss: 0.01363, time: 342.27502\n",
      "[RESULT]: Val. Epoch: 21, summary_loss: 0.01294, val_f1_score: 0.53933, val_acc_score: 0.55275, time: 44.07782\n",
      "\n",
      "2020-08-24T13:38:10.354592\n",
      "LR: 0.0005936906572928622\n",
      "[RESULT]: Train. Epoch: 22, summary_loss: 0.01342, time: 341.67489\n",
      "[RESULT]: Val. Epoch: 22, summary_loss: 0.01158, val_f1_score: 0.56132, val_acc_score: 0.57684, time: 42.31842\n",
      "\n",
      "2020-08-24T13:44:36.278503\n",
      "LR: 0.000562666616782152\n",
      "[RESULT]: Train. Epoch: 23, summary_loss: 0.01321, time: 342.67343\n",
      "[RESULT]: Val. Epoch: 23, summary_loss: 0.01136, val_f1_score: 0.56140, val_acc_score: 0.57825, time: 45.43737\n",
      "\n",
      "2020-08-24T13:51:06.528329\n",
      "LR: 0.0005313952597646566\n",
      "[RESULT]: Train. Epoch: 24, summary_loss: 0.01320, time: 341.13315\n",
      "[RESULT]: Val. Epoch: 24, summary_loss: 0.01197, val_f1_score: 0.56792, val_acc_score: 0.58339, time: 45.95166\n",
      "\n",
      "2020-08-24T13:57:34.965699\n",
      "LR: 0.0004999999999999998\n",
      "[RESULT]: Train. Epoch: 25, summary_loss: 0.01288, time: 341.41735\n",
      "[RESULT]: Val. Epoch: 25, summary_loss: 0.01143, val_f1_score: 0.58399, val_acc_score: 0.59673, time: 42.06001\n",
      "early stopping: Epoch: 26\n",
      "\n",
      "2020-08-24T14:03:59.786636\n",
      "LR: 0.00046860474023534314\n",
      "[RESULT]: Train. Epoch: 26, summary_loss: 0.01284, time: 343.60843\n",
      "[RESULT]: Val. Epoch: 26, summary_loss: 0.01128, val_f1_score: 0.58455, val_acc_score: 0.59696, time: 70.91318\n",
      "early stopping: Epoch: 27\n",
      "\n",
      "2020-08-24T14:10:56.312833\n",
      "LR: 0.00043733338321784774\n",
      "[RESULT]: Train. Epoch: 27, summary_loss: 0.01264, time: 381.30447\n",
      "[RESULT]: Val. Epoch: 27, summary_loss: 0.01245, val_f1_score: 0.57041, val_acc_score: 0.57825, time: 80.35140\n",
      "\n",
      "2020-08-24T14:18:38.689153\n",
      "LR: 0.00040630934270713756\n",
      "[RESULT]: Train. Epoch: 28, summary_loss: 0.01261, time: 406.39340\n",
      "[RESULT]: Val. Epoch: 28, summary_loss: 0.01299, val_f1_score: 0.56306, val_acc_score: 0.57380, time: 70.89361\n",
      "\n",
      "2020-08-24T14:26:36.733119\n",
      "LR: 0.00037565505641757246\n",
      "[RESULT]: Train. Epoch: 29, summary_loss: 0.01237, time: 434.69772\n",
      "[RESULT]: Val. Epoch: 29, summary_loss: 0.01189, val_f1_score: 0.59436, val_acc_score: 0.60211, time: 95.34449\n",
      "\n",
      "2020-08-24T14:35:28.343761\n",
      "LR: 0.00034549150281252633\n",
      "[RESULT]: Train. Epoch: 30, summary_loss: 0.01237, time: 417.46616\n",
      "[RESULT]: Val. Epoch: 30, summary_loss: 0.01185, val_f1_score: 0.59366, val_acc_score: 0.60211, time: 84.92242\n",
      "\n",
      "2020-08-24T14:43:51.464687\n",
      "LR: 0.00031593772365766105\n",
      "[RESULT]: Train. Epoch: 31, summary_loss: 0.01216, time: 395.08386\n",
      "[RESULT]: Val. Epoch: 31, summary_loss: 0.01138, val_f1_score: 0.59503, val_acc_score: 0.60772, time: 73.88581\n",
      "\n",
      "2020-08-24T14:51:41.833958\n",
      "LR: 0.00028711035421746355\n",
      "[RESULT]: Train. Epoch: 32, summary_loss: 0.01220, time: 394.14500\n",
      "[RESULT]: Val. Epoch: 32, summary_loss: 0.01113, val_f1_score: 0.59977, val_acc_score: 0.61333, time: 77.77323\n",
      "\n",
      "2020-08-24T14:59:35.624274\n",
      "LR: 0.0002591231629491422\n",
      "[RESULT]: Train. Epoch: 33, summary_loss: 0.01195, time: 376.50772\n",
      "[RESULT]: Val. Epoch: 33, summary_loss: 0.01058, val_f1_score: 0.60466, val_acc_score: 0.61871, time: 71.19437\n",
      "\n",
      "2020-08-24T15:07:05.240815\n",
      "LR: 0.00023208660251050145\n",
      "[RESULT]: Train. Epoch: 34, summary_loss: 0.01202, time: 362.69869\n",
      "[RESULT]: Val. Epoch: 34, summary_loss: 0.01116, val_f1_score: 0.60298, val_acc_score: 0.61637, time: 69.17792\n",
      "\n",
      "2020-08-24T15:14:17.819844\n",
      "LR: 0.00020610737385376337\n",
      "[RESULT]: Train. Epoch: 35, summary_loss: 0.01187, time: 355.07198\n",
      "[RESULT]: Val. Epoch: 35, summary_loss: 0.01116, val_f1_score: 0.61316, val_acc_score: 0.62596, time: 62.41614\n",
      "\n",
      "2020-08-24T15:21:16.913536\n",
      "LR: 0.00018128800512565502\n",
      "[RESULT]: Train. Epoch: 36, summary_loss: 0.01189, time: 350.96860\n",
      "[RESULT]: Val. Epoch: 36, summary_loss: 0.01069, val_f1_score: 0.61149, val_acc_score: 0.62924, time: 75.80184\n",
      "\n",
      "2020-08-24T15:28:24.531813\n",
      "LR: 0.00015772644703565555\n",
      "[RESULT]: Train. Epoch: 37, summary_loss: 0.01179, time: 370.84453\n",
      "[RESULT]: Val. Epoch: 37, summary_loss: 0.01106, val_f1_score: 0.60545, val_acc_score: 0.62292, time: 75.13232\n",
      "\n",
      "2020-08-24T15:35:51.172435\n",
      "LR: 0.00013551568628929425\n",
      "[RESULT]: Train. Epoch: 38, summary_loss: 0.01164, time: 370.96868\n",
      "[RESULT]: Val. Epoch: 38, summary_loss: 0.01057, val_f1_score: 0.62144, val_acc_score: 0.63860, time: 77.69666\n",
      "\n",
      "2020-08-24T15:43:21.688562\n",
      "LR: 0.00011474337861210535\n",
      "[RESULT]: Train. Epoch: 39, summary_loss: 0.01152, time: 373.47576\n",
      "[RESULT]: Val. Epoch: 39, summary_loss: 0.01094, val_f1_score: 0.61528, val_acc_score: 0.63298, time: 82.94706\n",
      "\n",
      "2020-08-24T15:50:58.819615\n",
      "LR: 9.549150281252626e-05\n",
      "[RESULT]: Train. Epoch: 40, summary_loss: 0.01155, time: 429.45429\n",
      "[RESULT]: Val. Epoch: 40, summary_loss: 0.01049, val_f1_score: 0.63254, val_acc_score: 0.64421, time: 89.89962\n",
      "\n",
      "2020-08-24T15:59:40.040383\n",
      "LR: 7.783603724899252e-05\n",
      "[RESULT]: Train. Epoch: 41, summary_loss: 0.01151, time: 372.43073\n",
      "[RESULT]: Val. Epoch: 41, summary_loss: 0.01080, val_f1_score: 0.61119, val_acc_score: 0.62596, time: 81.82720\n",
      "\n",
      "2020-08-24T16:07:14.990794\n",
      "LR: 6.184665997806817e-05\n",
      "[RESULT]: Train. Epoch: 42, summary_loss: 0.01141, time: 354.02065\n",
      "[RESULT]: Val. Epoch: 42, summary_loss: 0.01075, val_f1_score: 0.62105, val_acc_score: 0.63485, time: 58.65388\n",
      "\n",
      "2020-08-24T16:14:08.423801\n",
      "LR: 4.7586473766990294e-05\n",
      "[RESULT]: Train. Epoch: 43, summary_loss: 0.01143, time: 355.72286\n",
      "[RESULT]: Val. Epoch: 43, summary_loss: 0.01037, val_f1_score: 0.63336, val_acc_score: 0.64725, time: 67.43622\n",
      "\n",
      "2020-08-24T16:21:13.610827\n",
      "LR: 3.5111757055874305e-05\n",
      "[RESULT]: Train. Epoch: 44, summary_loss: 0.01131, time: 355.23770\n",
      "[RESULT]: Val. Epoch: 44, summary_loss: 0.01074, val_f1_score: 0.61614, val_acc_score: 0.63485, time: 69.97672\n",
      "\n",
      "2020-08-24T16:28:19.500205\n",
      "LR: 2.4471741852423218e-05\n",
      "[RESULT]: Train. Epoch: 45, summary_loss: 0.01136, time: 352.68990\n",
      "[RESULT]: Val. Epoch: 45, summary_loss: 0.01057, val_f1_score: 0.62001, val_acc_score: 0.63813, time: 65.25049\n",
      "\n",
      "2020-08-24T16:35:18.158674\n",
      "LR: 1.5708419435684507e-05\n",
      "[RESULT]: Train. Epoch: 46, summary_loss: 0.01136, time: 352.00349\n",
      "[RESULT]: Val. Epoch: 46, summary_loss: 0.01078, val_f1_score: 0.62135, val_acc_score: 0.63977, time: 64.76258\n",
      "\n",
      "2020-08-24T16:42:15.604944\n",
      "LR: 8.856374635655634e-06\n",
      "[RESULT]: Train. Epoch: 47, summary_loss: 0.01134, time: 361.47978\n",
      "[RESULT]: Val. Epoch: 47, summary_loss: 0.01085, val_f1_score: 0.61712, val_acc_score: 0.63135, time: 82.59275\n",
      "\n",
      "2020-08-24T16:49:40.387324\n",
      "LR: 3.942649342761115e-06\n",
      "[RESULT]: Train. Epoch: 48, summary_loss: 0.01134, time: 428.98751\n",
      "[RESULT]: Val. Epoch: 48, summary_loss: 0.01073, val_f1_score: 0.61679, val_acc_score: 0.63205, time: 97.29082\n",
      "\n",
      "2020-08-24T16:58:27.411802\n",
      "LR: 9.866357858642198e-07\n",
      "[RESULT]: Train. Epoch: 49, summary_loss: 0.01136, time: 437.91894\n",
      "[RESULT]: Val. Epoch: 49, summary_loss: 0.01054, val_f1_score: 0.62021, val_acc_score: 0.63462, time: 101.95715\n"
     ]
    }
   ],
   "source": [
    "net = get_model(num_classes=config.num_class, pretrained=True)\n",
    "run_training(net, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 2.078157,
     "end_time": "2020-08-24T17:07:32.628117",
     "exception": false,
     "start_time": "2020-08-24T17:07:30.549960",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## OOF(Simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T17:07:37.021887Z",
     "iopub.status.busy": "2020-08-24T17:07:37.021221Z",
     "iopub.status.idle": "2020-08-24T17:07:37.081023Z",
     "shell.execute_reply": "2020-08-24T17:07:37.080061Z"
    },
    "papermill": {
     "duration": 2.381693,
     "end_time": "2020-08-24T17:07:37.081157",
     "exception": false,
     "start_time": "2020-08-24T17:07:34.699464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INV_BIRD_CODE = {v: k for k, v in BIRD_CODE.items()}\n",
    "val_true = train_all.query(\"fold == @use_fold\")[\"ebird_code\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T17:07:41.189788Z",
     "iopub.status.busy": "2020-08-24T17:07:41.188854Z",
     "iopub.status.idle": "2020-08-24T17:07:41.196688Z",
     "shell.execute_reply": "2020-08-24T17:07:41.197319Z"
    },
    "papermill": {
     "duration": 2.053539,
     "end_time": "2020-08-24T17:07:41.197505",
     "exception": false,
     "start_time": "2020-08-24T17:07:39.143966",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def row_wise_f1_score_micro(y_true, y_pred):\n",
    "    \"\"\" author @shonenkov \"\"\"\n",
    "    F1 = []\n",
    "    for preds, trues in zip(y_pred, y_true):\n",
    "        TP, FN, FP = 0, 0, 0\n",
    "        preds = preds.split()\n",
    "        trues = trues.split()\n",
    "        for true in trues:\n",
    "            if true in preds:\n",
    "                TP += 1\n",
    "            else:\n",
    "                FN += 1\n",
    "        for pred in preds:\n",
    "            if pred not in trues:\n",
    "                FP += 1\n",
    "        F1.append(2*TP / (2*TP + FN + FP))\n",
    "    return np.mean(F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T17:07:45.783766Z",
     "iopub.status.busy": "2020-08-24T17:07:45.783035Z",
     "iopub.status.idle": "2020-08-24T17:07:49.073957Z",
     "shell.execute_reply": "2020-08-24T17:07:49.075066Z"
    },
    "papermill": {
     "duration": 5.527456,
     "end_time": "2020-08-24T17:07:49.075248",
     "exception": false,
     "start_time": "2020-08-24T17:07:43.547792",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load pretrain weight: panns/best-checkpoint-040epoch.bin\n"
     ]
    }
   ],
   "source": [
    "def get_trained_model(weight_path=None):\n",
    "    \n",
    "    model_config = {\n",
    "        \"sample_rate\": 32000,\n",
    "        \"window_size\": 1024,\n",
    "        \"hop_size\": 320,\n",
    "        \"mel_bins\": 64,\n",
    "        \"fmin\": 50,\n",
    "        \"fmax\": 14000,\n",
    "        \"classes_num\":264\n",
    "        }\n",
    "\n",
    "    model = Transfer_Cnn14(**model_config)\n",
    "    if weight_path:\n",
    "        print(\"load pretrain weight: {}\".format(weight_path))\n",
    "        weights = torch.load(weight_path, map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(weights['model_state_dict'])\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    \n",
    "    return model\n",
    "\n",
    "best_weight_path = glob(f'{config.folder}/best-checkpoint-*epoch.bin')[-1]\n",
    "trained_net = get_trained_model(best_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T17:07:53.463207Z",
     "iopub.status.busy": "2020-08-24T17:07:53.461307Z",
     "iopub.status.idle": "2020-08-24T17:07:53.463975Z",
     "shell.execute_reply": "2020-08-24T17:07:53.464427Z"
    },
    "papermill": {
     "duration": 2.13736,
     "end_time": "2020-08-24T17:07:53.464555",
     "exception": false,
     "start_time": "2020-08-24T17:07:51.327195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(data.Dataset):\n",
    "    def __init__(self, file_list):\n",
    "        \n",
    "        self.file_list = file_list \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        \n",
    "        SR = 32000\n",
    "        wav_path, ebird_code = self.file_list[idx]\n",
    "        y, sr = sf.read(wav_path)\n",
    "        effective_length = sr * config.period\n",
    "        \n",
    "        if len(y) > effective_length:\n",
    "            y = y.astype(np.float32)\n",
    "            len_y = len(y)\n",
    "            start = 0\n",
    "            end = SR * 5\n",
    "            y_all = []\n",
    "            while len_y > start:\n",
    "                y_batch = y[start:end].astype(np.float32)\n",
    "                if len(y_batch) != (SR * 5):\n",
    "                    y_pad = np.zeros(5 * SR, dtype=np.float32)\n",
    "                    y_pad[:len(y_batch)] = y_batch\n",
    "                    y_all.append(y_pad)\n",
    "                    break\n",
    "                start = end\n",
    "                end = end + SR * 5\n",
    "                y_all.append(y_batch)\n",
    "            y_all = np.asarray(y_all)\n",
    "            return y_all\n",
    "        elif len(y) < effective_length:\n",
    "            new_wave = np.zeros(effective_length, dtype=y.dtype)\n",
    "            start = np.random.randint(effective_length - len(y))\n",
    "            new_wave[start:start + len(y)] = y\n",
    "            y = new_wave.astype(np.float32)\n",
    "        else:\n",
    "            y = y.astype(np.float32)\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T17:07:57.665806Z",
     "iopub.status.busy": "2020-08-24T17:07:57.663948Z",
     "iopub.status.idle": "2020-08-24T17:07:57.666475Z",
     "shell.execute_reply": "2020-08-24T17:07:57.666944Z"
    },
    "papermill": {
     "duration": 2.101557,
     "end_time": "2020-08-24T17:07:57.667075",
     "exception": false,
     "start_time": "2020-08-24T17:07:55.565518",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prediction(val_file_list, model, threshold):\n",
    "    \n",
    "    SR = 32000\n",
    "    period = config.period\n",
    "    dataset = TestDataset(val_file_list)\n",
    "    loader = data.DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    model.eval()\n",
    "    #j = 0\n",
    "    predictions = []\n",
    "    for wave in progress_bar(loader):\n",
    "\n",
    "        if wave.size()[1] == SR*period: \n",
    "            wave = wave.to(device).float()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                prediction = model(wave)\n",
    "                event_proba = prediction['clipwise_output'].detach().cpu().numpy().reshape(-1)\n",
    "                \n",
    "            events = proba >= threshold\n",
    "            labels = np.argwhere(events).reshape(-1).tolist()\n",
    "\n",
    "        else:\n",
    "            # to avoid prediction on large batch\n",
    "            wave = wave.squeeze(0)\n",
    "            batch_size = 16\n",
    "            whole_size = wave.size(0)\n",
    "            if whole_size % batch_size == 0:\n",
    "                n_iter = whole_size // batch_size\n",
    "            else:\n",
    "                n_iter = whole_size // batch_size + 1\n",
    "                \n",
    "            all_events = set()\n",
    "            for batch_i in range(n_iter):\n",
    "                batch = wave[batch_i * batch_size:(batch_i + 1) * batch_size]\n",
    "                if batch.ndim == 3:\n",
    "                    batch = batch.unsqueeze(0)\n",
    "\n",
    "                batch = batch.to(device)\n",
    "                with torch.no_grad():\n",
    "                    prediction = model(batch)\n",
    "                    proba = prediction['clipwise_output'].detach().cpu().numpy()\n",
    "                    \n",
    "                events = proba >= threshold\n",
    "                for i in range(len(events)):\n",
    "                    event = events[i, :]\n",
    "                    labels = np.argwhere(event).reshape(-1).tolist()\n",
    "                    for label in labels:\n",
    "                        all_events.add(label)\n",
    "                        \n",
    "            labels = list(all_events)\n",
    "        if len(labels) == 0:\n",
    "            predictions.append(\"nocall\")\n",
    "        else:\n",
    "            labels_str_list = list(map(lambda x: INV_BIRD_CODE[x], labels))\n",
    "            label_string = \" \".join(labels_str_list)\n",
    "            predictions.append(label_string)\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-08-24T17:08:01.904441Z",
     "iopub.status.busy": "2020-08-24T17:08:01.903673Z",
     "iopub.status.idle": "2020-08-24T17:08:01.907537Z",
     "shell.execute_reply": "2020-08-24T17:08:01.907020Z"
    },
    "papermill": {
     "duration": 1.960029,
     "end_time": "2020-08-24T17:08:01.907641",
     "exception": false,
     "start_time": "2020-08-24T17:07:59.947612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def threshold_optimization(val_file_list, val_true, model):\n",
    "    \n",
    "    best_score = 0.0\n",
    "    best_threshold = 0.0\n",
    "    for threshold in np.arange(0.1, 1.0, 0.1):\n",
    "        val_predict = prediction(val_file_list, model, threshold)\n",
    "        score = row_wise_f1_score_micro(val_true, val_predict)\n",
    "        \n",
    "        if score >= best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print(best_score, best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2020-08-24T17:08:06.080711Z",
     "iopub.status.busy": "2020-08-24T17:08:06.080026Z",
     "iopub.status.idle": "2020-08-24T18:09:04.228590Z",
     "shell.execute_reply": "2020-08-24T18:09:04.228072Z"
    },
    "papermill": {
     "duration": 3660.269153,
     "end_time": "2020-08-24T18:09:04.228764",
     "exception": false,
     "start_time": "2020-08-24T17:08:03.959611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4275' class='' max='4275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4275/4275 07:19<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4275' class='' max='4275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4275/4275 06:46<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4275' class='' max='4275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4275/4275 06:41<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4275' class='' max='4275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4275/4275 06:59<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4275' class='' max='4275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4275/4275 06:53<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4275' class='' max='4275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4275/4275 06:45<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4275' class='' max='4275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4275/4275 06:32<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4275' class='' max='4275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4275/4275 06:31<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4275' class='' max='4275' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [4275/4275 06:28<00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6808740927688296 0.8\n"
     ]
    }
   ],
   "source": [
    "threshold_optimization(val_file_list, val_true, model=trained_net)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "papermill": {
   "duration": 25227.772306,
   "end_time": "2020-08-24T18:09:07.605261",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-08-24T11:08:39.832955",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
